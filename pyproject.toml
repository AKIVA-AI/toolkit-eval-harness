[build-system]
requires = ["setuptools>=69", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "toolkit-eval-harness"
version = "0.1.0"
description = "Eval Harness: golden task suites + scoring + CI-friendly reports."
readme = "README.md"
requires-python = ">=3.10"
license = { text = "MIT" }
authors = [{ name = "Toolkit Contributors" }]
keywords = ["eval", "llm", "testing", "quality", "regression"]
classifiers = [
  "Development Status :: 3 - Alpha",
  "Intended Audience :: Developers",
  "Programming Language :: Python :: 3",
  "Programming Language :: Python :: 3 :: Only",
  "Programming Language :: Python :: 3.10",
  "Programming Language :: Python :: 3.11",
  "Programming Language :: Python :: 3.12",
  "Typing :: Typed",
]
dependencies = []

[project.urls]
Homepage = "https://github.com/AKIVA-AI/toolkit-eval-harness"
Repository = "https://github.com/AKIVA-AI/toolkit-eval-harness"
Issues = "https://github.com/AKIVA-AI/toolkit-eval-harness/issues"

[project.scripts]
toolkit-eval = "toolkit_eval_harness.cli:main"

[project.optional-dependencies]
signing = [
  "cryptography>=43.0.0",
]
dev = [
  "pytest>=8.0.0",
  "pytest-cov>=5.0.0",
  "ruff>=0.6.0",
  "pyright>=1.1.380",
  "cryptography>=43.0.0",
]

[tool.pytest.ini_options]
testpaths = ["tests"]

[tool.coverage.run]
branch = true
source = ["toolkit_eval_harness"]
omit = ["*/toolkit_eval_harness/__main__.py"]

[tool.coverage.report]
show_missing = true
skip_covered = true
fail_under = 60

[tool.ruff]
line-length = 100
target-version = "py310"

[tool.ruff.lint]
select = ["E", "F", "I", "B", "UP"]

[tool.ruff.lint.isort]
known-first-party = ["toolkit_eval_harness"]

[tool.setuptools]
package-dir = { "" = "src" }
include-package-data = true

[tool.setuptools.packages.find]
where = ["src"]

[tool.setuptools.package-data]
toolkit_eval_harness = ["py.typed"]
